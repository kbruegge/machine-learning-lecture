{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a42f6dc",
   "metadata": {},
   "source": [
    "# Short Introduction to Neural Networks and Deep Learning with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fea58a",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Table of Contents</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d86167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Resize, Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b553b9",
   "metadata": {},
   "source": [
    "# How to define a Neural Network Architecture in Torch\n",
    "\n",
    "To declare a new Network architecture, we create a new class inheriting from `torch.nn.Model`.\n",
    "\n",
    "The simplest way to declare a Network architecture is to declare the sequence of layers using `torch.nn.Sequential`\n",
    "in `__init__` and we have to implement the `forward` pass. The rest is taken care of by torch (gradients, backword propagation, ...) automagically.\n",
    "\n",
    "Torch builds a computational graph, that can be executed (on different devices) and transformed (e.g. calculate the gradient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c7554",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, input_size, n_classes, dropout=0.25, n_hidden=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, n_hidden),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_classes),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc_stack(x)\n",
    "        return x\n",
    "    \n",
    "FullyConnected(input_size=3 * 50 * 50, n_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f24277b",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Unfortunately, training the network is not as simple as calling `fit` like in sklearn.\n",
    "Torch is a very flexible framework, and we have to decide for the data loader, loss function, the optimizer, the model, device and how we evaluate the performance on the test data set.\n",
    "\n",
    "In the end, we are going to write our own `fit` function, to make it simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435aef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cpu\"\n",
    "# uncomment to use GPU if available\n",
    "# CPU offers better debugging\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a43b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, device=DEVICE):    \n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        \n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "       \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # store loss for plotting\n",
    "        losses.append(loss.item())\n",
    "    return losses\n",
    "\n",
    "            \n",
    "def test(dataloader, model, loss_fn, device=DEVICE):\n",
    "    model = model.to(device)\n",
    "    test_losses = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_losses.append(loss_fn(pred, y).item())\n",
    "\n",
    "    return test_losses\n",
    "\n",
    "\n",
    "def fit_one_epoch(train_dataloader, test_dataloader, model, loss_fn, optimizer, device=DEVICE):\n",
    "    train_losses = train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "    test_losses = test(test_dataloader, model, loss_fn, device)\n",
    "    return train_losses, test_losses\n",
    "\n",
    "\n",
    "def accuracy(dataloader, model, device=DEVICE):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model = model.to(device)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            total += len(y)\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cfebec",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dca0824",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    transform=Compose([Resize((8, 8)), ToTensor()]),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "mnist_test = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    transform=Compose([Resize((8, 8)), ToTensor()]),\n",
    "    download=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f71853",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(mnist_train, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(mnist_test, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# get first batch\n",
    "X, y = next(iter(test_dataloader))\n",
    "\n",
    "print(\"Shape of X: \", X.shape)\n",
    "print(\"Shape of y: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bed474",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 5, figsize=(9, 3), constrained_layout=True)\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(X[i, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f11b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "model = FullyConnected(\n",
    "    input_size=X[0].shape.numel(),\n",
    "    n_classes=len(mnist_train.classes),\n",
    "    n_hidden=512,\n",
    "    dropout=0.75,\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "test_losses = []\n",
    "train_losses = []\n",
    "\n",
    "print(f'Test Accuracy: {accuracy(test_dataloader, model):.1%}')\n",
    "\n",
    "for t in tqdm(range(epochs)):\n",
    "    epoch_loss_train, epoch_loss_test = fit_one_epoch(\n",
    "        train_dataloader, test_dataloader, model, loss_fn, optimizer\n",
    "    )\n",
    "    train_losses.append(epoch_loss_train)\n",
    "    test_losses.append(epoch_loss_test)\n",
    "    print(f'Test Accuracy: {accuracy(test_dataloader, model):.1%}')\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, test_losses):\n",
    "    plt.figure()\n",
    "    \n",
    "    for i, (label, losses) in enumerate(zip((\"Train\", \"Test\"), (train_losses, test_losses))):\n",
    "        losses = np.array(losses)\n",
    "       \n",
    "        x = np.linspace(0, len(losses), losses.size)\n",
    "        plt.plot(x, losses.ravel(), label=f'Loss {label}', color=f'C{i}', alpha=0.5)\n",
    "                \n",
    "        mean_loss = losses.mean(axis=1)\n",
    "        x = np.arange(0.5, len(mean_loss))\n",
    "        plt.plot(x, mean_loss, label=f'Mean Epoch Loss {label}', color=f'C{i}', zorder=3)\n",
    "        \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf4e9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6fee71",
   "metadata": {},
   "source": [
    "# CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91821c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_train = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "cifar10_test = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c9611",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(cifar10_train, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(cifar10_test, batch_size=batch_size)\n",
    "\n",
    "# get first batch\n",
    "X, y = next(iter(test_dataloader))\n",
    "\n",
    "print(\"Shape of X: \", X.shape)\n",
    "print(\"Shape of y: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc54c5a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4, figsize=(9, 9), constrained_layout=True)\n",
    "\n",
    "for idx, ax in enumerate(axs.flat):\n",
    "    img = np.swapaxes(X[idx], 1, 2).T\n",
    "    \n",
    "\n",
    "    ax.set_title(cifar10_train.classes[y[idx]])\n",
    "    ax.imshow(img)\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d95256",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FullyConnected(\n",
    "    input_size=X[0].shape.numel(),\n",
    "    n_classes=len(cifar10_train.classes),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30310f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "test_losses = []\n",
    "train_losses = []\n",
    "\n",
    "print(f'Test Accuracy: {accuracy(test_dataloader, model):.1%}')\n",
    "\n",
    "epochs = 15\n",
    "for t in tqdm(range(epochs)):\n",
    "    epoch_loss_train, epoch_loss_test = fit_one_epoch(\n",
    "        train_dataloader, test_dataloader, model, loss_fn, optimizer\n",
    "    )\n",
    "    train_losses.append(epoch_loss_train)\n",
    "    test_losses.append(epoch_loss_test)\n",
    "    print(f'Test Accuracy: {accuracy(test_dataloader, model):.1%}')\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0f93bc",
   "metadata": {},
   "source": [
    "We do not get much better than 40 % with a fully connected network.\n",
    "\n",
    "Let's try a deep learning network with convolutional layers. The architecture follows the one proposed here:\n",
    "https://arxiv.org/abs/1409.1556\n",
    "\n",
    "> Very Deep Convolutional Networks for Large-Scale Image Recognition  \n",
    "> Karen Simonyan, Andrew Zisserman\n",
    "\n",
    "> In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc77cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_stack = nn.Sequential(\n",
    "            # 1st stack of conv layers\n",
    "            nn.Conv2d(3, 32, kernel_size=(3, 3), padding='same'),\n",
    "            nn.Conv2d(32, 32, kernel_size=(3, 3), padding='same'),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "            # 2nd stack\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), padding='same'),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), padding='same'),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "            # 3rd stack\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), padding='same'),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), padding='same'),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(128 * 4 * 4, 128),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cedbcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvolutionalNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4388223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "test_losses = []\n",
    "train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787fde22",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "\n",
    "print(f'Test Accuracy: {accuracy(test_dataloader, model):.1%}')\n",
    "\n",
    "for t in tqdm(range(epochs)):\n",
    "    epoch_loss_train, epoch_loss_test = fit_one_epoch(\n",
    "        train_dataloader, test_dataloader, model, loss_fn, optimizer\n",
    "    )\n",
    "    train_losses.append(epoch_loss_train)\n",
    "    test_losses.append(epoch_loss_test)\n",
    "    print(f'Epoch {t:02d}: test accuracy = {accuracy(test_dataloader, model):.1%}')\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c820f23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses=train_losses, test_losses=test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a464d277",
   "metadata": {},
   "source": [
    "## FACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e63579",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -LO https://factdata.app.tu-dortmund.de/smd/smd_deeplearning_gammas.hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a9bc6",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "We need to implement our own data reader for the FACT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feef9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import tables\n",
    "\n",
    "class FACTData(Dataset):\n",
    "    def __init__(self, min_charge=20, train=True):\n",
    "        with tables.open_file('smd_deeplearning_gammas.hdf5') as f:\n",
    "            X = f.root.events.photons[:].astype(np.float32)\n",
    "            y = np.log10(f.root.events.corsika_event_header_total_energy[:].astype(np.float32))\n",
    "\n",
    "        # replace nans with 0\n",
    "        np.nan_to_num(X, copy=False)\n",
    "                \n",
    "        # select only bright events\n",
    "        mask = X.max(axis=(1, 2)) > min_charge\n",
    "        \n",
    "        X = X[mask]\n",
    "        y = y[mask]\n",
    "        \n",
    "        \n",
    "        # insert channel axis for torch\n",
    "        X = X[:, np.newaxis, :, :]\n",
    "        y = y[:, np.newaxis]\n",
    "        \n",
    "        # sample train / test events\n",
    "        rng = np.random.default_rng(0)\n",
    "        train_mask = rng.binomial(1, 0.75, len(X)).astype(bool)\n",
    "        \n",
    "        if train:\n",
    "            self.X = X[train_mask]\n",
    "            self.y = y[train_mask]\n",
    "        else:\n",
    "            self.X = X[~train_mask]\n",
    "            self.y = y[~train_mask]\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598988db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fact_data_train = FACTData(train=True)\n",
    "fact_data_test = FACTData(train=False)\n",
    "\n",
    "print(len(fact_data_train), len(fact_data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "    \n",
    "    \n",
    "fig = plt.figure(constrained_layout=True)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "img = ax.imshow(fact_data_test[0][0][0], cmap='inferno')\n",
    "cbar = fig.colorbar(img, ax=ax)\n",
    "\n",
    "def plot(event=0):\n",
    "    img.set_array(fact_data_test[event][0][0])\n",
    "    img.autoscale()\n",
    "    cbar.update_normal(img)\n",
    "    ax.set_title(f'E = {10**fact_data_test[event][1][0]:.1f} GeV')\n",
    "    \n",
    "interact(plot, event=(0, len(fact_data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1900f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ca01d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(fact_data_train, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(fact_data_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "X, y = next(iter(train_dataloader))\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45858f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(out_channels, dropout):\n",
    "    return [\n",
    "        nn.LazyConv2d(out_channels, kernel_size=(3, 3), padding='same'),\n",
    "        nn.LazyConv2d(out_channels, kernel_size=(3, 3), padding='same'),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Dropout(dropout),\n",
    "    ]\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_stack = nn.Sequential(\n",
    "            *layer(32, 0.25),\n",
    "            *layer(64, 0.25),\n",
    "            *layer(128, 0.25),\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        n_neurons = 256\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.LazyLinear(n_neurons),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_neurons, n_neurons),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_neurons, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5b862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db21183",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_stack = nn.Sequential(\n",
    "            # 1st stack of conv layers\n",
    "            nn.Conv2d(1, 32, kernel_size=(3, 3), padding='same'),\n",
    "            nn.Conv2d(32, 32, kernel_size=(3, 3), padding='same'),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "            # 2nd stack\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), padding='same'),\n",
    "            nn.Conv2d(64, 64, kernel_size=(3, 3), padding='same'),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "            # 3rd stack\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), padding='same'),\n",
    "            nn.Conv2d(128, 128, kernel_size=(3, 3), padding='same'),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(128 * 6 * 6, 128),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class SimpleConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_stack = nn.Sequential(\n",
    "            # 1st stack of conv layers\n",
    "            nn.Conv2d(1, 10, kernel_size=(5, 5), padding='same'),\n",
    "            nn.Conv2d(10, 10, kernel_size=(5, 5), padding='same'),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # 2rd stack\n",
    "            nn.Conv2d(10, 10, kernel_size=(5, 5), padding='same'),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(10 * 12 * 12, 128),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5448479",
   "metadata": {},
   "outputs": [],
   "source": [
    "12 * 12 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b5107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleConvolutionalNetwork()\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca3720",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042d147",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "\n",
    "for t in tqdm(range(epochs)):\n",
    "    epoch_loss_train, epoch_loss_test = fit_one_epoch(\n",
    "        train_dataloader, test_dataloader, model, loss_fn, optimizer, device='cpu'\n",
    "    )\n",
    "    train_losses.append(epoch_loss_train)\n",
    "    test_losses.append(epoch_loss_test)\n",
    "   \n",
    "    print(f'Epoch {t:3d}: test loss = {np.mean(test_losses[-1]):.3f}, train loss = {np.mean(train_losses[-1]):.3f}')\n",
    "\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7156d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(test_losses=test_losses, train_losses=train_losses)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3920eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "labels = []\n",
    "for X, y in train_dataloader:\n",
    "    labels.append(y)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(X.to(DEVICE))\n",
    "        predictions.append(pred.cpu())\n",
    "    \n",
    "predictions = np.concatenate(predictions)[:, 0]\n",
    "labels = np.concatenate(labels)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c39143",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape, predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1b38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist2d(labels, predictions, bins=100, range=[[2.5, 4], [2.5, 4]])\n",
    "plt.axline([1, 1], [1.1, 1.1], color='lightgray')\n",
    "plt.gca().set_aspect(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
